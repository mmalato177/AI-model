{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **MODELO S**\n",
    "Com data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importações e Definições de Seed**\n",
    "\n",
    "Primeiro, importamos as bibliotecas necessárias e definimos a seed para garantir a reprodutibilidade dos resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 18:28:35.768302: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-22 18:28:36.967347: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Definição dos Diretórios do Dataset e Tamanho da Imagem**\n",
    "\n",
    "Definimos os diretórios dos conjuntos de dados e o tamanho das imagens.\n",
    "Juntamos as imagens de treino todas na mesma pastas para simplificar o carregamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../Data/train'\n",
    "validation_dir = '../Data/validation5'\n",
    "test_dir = '../Data/test'\n",
    "IMG_SIZE = 32\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funções para Visualizaçao de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history, test_number, trial_number):\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'../plots/s{test_number}/trial_{trial_number}_plot.png')\n",
    "\n",
    "    plt.close()\n",
    "    return\n",
    "\n",
    "\n",
    "def predict_with_best_model(model, dataset):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for x, y in dataset:\n",
    "        y_true.extend(tf.argmax(y, axis=1))\n",
    "        y_pred.extend(tf.argmax(model.predict(x), axis=1))\n",
    "\n",
    "    return y_true, y_pred\n",
    "\n",
    "# Função para plotar matriz de confusão\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names, test_number,trial_number):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.xlabel('Predicted labels')\n",
    "    plt.ylabel('True labels')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig(f'../plots/s{test_number}/trial_{trial_number}_confusion_matrix.png')\n",
    "\n",
    "    plt.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Carregamento dos Conjuntos de Dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 40000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n",
      "Found 10000 files belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    validation_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32,\n",
    "    seed=SEED\n",
    ")\n",
    "\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    label_mode='categorical',\n",
    "    image_size=(IMG_SIZE, IMG_SIZE),\n",
    "    batch_size=32,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Definição da data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data augmentation using keras.Sequential\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(factor=0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 21:28:46.625793: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_dataset.take(1):\n",
    "    for i in range(4):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        ax = plt.subplot(2, 2, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Normalização dos Conjuntos de Dados**\n",
    "\n",
    "Normalizamos os conjuntos de dados para garantir que os valores dos pixels estejam na faixa de 0 a 1 o que são mais adequados ao modelo de treino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalization_layer = layers.Rescaling(1./255)\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    ")\n",
    "\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    ")\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda x, y: (normalization_layer(x), y)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construção do modelo 1 \n",
    "Baseado no modelo 3 dos testes anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filters_1 = 32\n",
    "num_filters_2 = 32\n",
    "num_filters_3 = 64\n",
    "optimizer_name = 'Adam'\n",
    "learning_rate = 3e-4\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model.add(layers.Conv2D(num_filters_1, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model.add(layers.Conv2D(num_filters_2, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Terceira camada convolucional\n",
    "model.add(layers.Conv2D(num_filters_3, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Camadas flatten e dense\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = getattr(optimizers, optimizer_name)(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinar o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 19:24:07.238341: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/sequential_15_1/dropout_49_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2456 - loss: 2.5211\n",
      "Epoch 1: val_loss improved from inf to 1.51678, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - accuracy: 0.2456 - loss: 2.5205 - val_accuracy: 0.4520 - val_loss: 1.5168 - learning_rate: 3.0000e-04\n",
      "Epoch 2/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3847 - loss: 1.7399\n",
      "Epoch 2: val_loss improved from 1.51678 to 1.34610, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.3848 - loss: 1.7398 - val_accuracy: 0.5187 - val_loss: 1.3461 - learning_rate: 3.0000e-04\n",
      "Epoch 3/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4414 - loss: 1.5521\n",
      "Epoch 3: val_loss did not improve from 1.34610\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.4414 - loss: 1.5521 - val_accuracy: 0.5085 - val_loss: 1.3962 - learning_rate: 3.0000e-04\n",
      "Epoch 4/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4742 - loss: 1.4591\n",
      "Epoch 4: val_loss improved from 1.34610 to 1.29845, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.4742 - loss: 1.4590 - val_accuracy: 0.5415 - val_loss: 1.2984 - learning_rate: 3.0000e-04\n",
      "Epoch 5/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4967 - loss: 1.3983\n",
      "Epoch 5: val_loss did not improve from 1.29845\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.4967 - loss: 1.3983 - val_accuracy: 0.5384 - val_loss: 1.3212 - learning_rate: 3.0000e-04\n",
      "Epoch 6/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5110 - loss: 1.3623\n",
      "Epoch 6: val_loss did not improve from 1.29845\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5110 - loss: 1.3623 - val_accuracy: 0.5262 - val_loss: 1.3536 - learning_rate: 3.0000e-04\n",
      "Epoch 7/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5334 - loss: 1.3149\n",
      "Epoch 7: val_loss improved from 1.29845 to 1.15093, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5334 - loss: 1.3149 - val_accuracy: 0.5944 - val_loss: 1.1509 - learning_rate: 3.0000e-04\n",
      "Epoch 8/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5388 - loss: 1.2904\n",
      "Epoch 8: val_loss did not improve from 1.15093\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5388 - loss: 1.2904 - val_accuracy: 0.5626 - val_loss: 1.3018 - learning_rate: 3.0000e-04\n",
      "Epoch 9/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5501 - loss: 1.2660\n",
      "Epoch 9: val_loss did not improve from 1.15093\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5501 - loss: 1.2660 - val_accuracy: 0.5312 - val_loss: 1.3892 - learning_rate: 3.0000e-04\n",
      "Epoch 10/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5602 - loss: 1.2382\n",
      "Epoch 10: val_loss did not improve from 1.15093\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5603 - loss: 1.2382 - val_accuracy: 0.5815 - val_loss: 1.2378 - learning_rate: 3.0000e-04\n",
      "Epoch 11/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5634 - loss: 1.2213\n",
      "Epoch 11: val_loss improved from 1.15093 to 1.07170, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5634 - loss: 1.2213 - val_accuracy: 0.6254 - val_loss: 1.0717 - learning_rate: 3.0000e-04\n",
      "Epoch 12/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5759 - loss: 1.1938\n",
      "Epoch 12: val_loss did not improve from 1.07170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5759 - loss: 1.1937 - val_accuracy: 0.6064 - val_loss: 1.1443 - learning_rate: 3.0000e-04\n",
      "Epoch 13/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5817 - loss: 1.1778\n",
      "Epoch 13: val_loss did not improve from 1.07170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5817 - loss: 1.1778 - val_accuracy: 0.6052 - val_loss: 1.1513 - learning_rate: 3.0000e-04\n",
      "Epoch 14/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5891 - loss: 1.1607\n",
      "Epoch 14: val_loss improved from 1.07170 to 1.04419, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5891 - loss: 1.1607 - val_accuracy: 0.6417 - val_loss: 1.0442 - learning_rate: 3.0000e-04\n",
      "Epoch 15/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5938 - loss: 1.1438\n",
      "Epoch 15: val_loss improved from 1.04419 to 0.95581, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5938 - loss: 1.1438 - val_accuracy: 0.6606 - val_loss: 0.9558 - learning_rate: 3.0000e-04\n",
      "Epoch 16/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5986 - loss: 1.1293\n",
      "Epoch 16: val_loss did not improve from 0.95581\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5986 - loss: 1.1292 - val_accuracy: 0.6421 - val_loss: 1.0236 - learning_rate: 3.0000e-04\n",
      "Epoch 17/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6033 - loss: 1.1172\n",
      "Epoch 17: val_loss improved from 0.95581 to 0.94740, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6033 - loss: 1.1172 - val_accuracy: 0.6663 - val_loss: 0.9474 - learning_rate: 3.0000e-04\n",
      "Epoch 18/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6131 - loss: 1.0956\n",
      "Epoch 18: val_loss improved from 0.94740 to 0.93378, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6131 - loss: 1.0956 - val_accuracy: 0.6722 - val_loss: 0.9338 - learning_rate: 3.0000e-04\n",
      "Epoch 19/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6137 - loss: 1.0903\n",
      "Epoch 19: val_loss improved from 0.93378 to 0.93358, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6137 - loss: 1.0903 - val_accuracy: 0.6761 - val_loss: 0.9336 - learning_rate: 3.0000e-04\n",
      "Epoch 20/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6177 - loss: 1.0868\n",
      "Epoch 20: val_loss improved from 0.93358 to 0.93166, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6177 - loss: 1.0868 - val_accuracy: 0.6765 - val_loss: 0.9317 - learning_rate: 3.0000e-04\n",
      "Epoch 21/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6243 - loss: 1.0701\n",
      "Epoch 21: val_loss did not improve from 0.93166\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6243 - loss: 1.0701 - val_accuracy: 0.6575 - val_loss: 0.9830 - learning_rate: 3.0000e-04\n",
      "Epoch 22/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6303 - loss: 1.0550\n",
      "Epoch 22: val_loss improved from 0.93166 to 0.89221, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 31ms/step - accuracy: 0.6303 - loss: 1.0549 - val_accuracy: 0.6885 - val_loss: 0.8922 - learning_rate: 3.0000e-04\n",
      "Epoch 23/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6301 - loss: 1.0568\n",
      "Epoch 23: val_loss did not improve from 0.89221\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6301 - loss: 1.0568 - val_accuracy: 0.6908 - val_loss: 0.8949 - learning_rate: 3.0000e-04\n",
      "Epoch 24/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6376 - loss: 1.0444\n",
      "Epoch 24: val_loss improved from 0.89221 to 0.87025, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6376 - loss: 1.0444 - val_accuracy: 0.6966 - val_loss: 0.8702 - learning_rate: 3.0000e-04\n",
      "Epoch 25/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6346 - loss: 1.0384\n",
      "Epoch 25: val_loss did not improve from 0.87025\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6346 - loss: 1.0384 - val_accuracy: 0.6782 - val_loss: 0.9565 - learning_rate: 3.0000e-04\n",
      "Epoch 26/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6389 - loss: 1.0289\n",
      "Epoch 26: val_loss did not improve from 0.87025\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6389 - loss: 1.0289 - val_accuracy: 0.6739 - val_loss: 0.9497 - learning_rate: 3.0000e-04\n",
      "Epoch 27/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6384 - loss: 1.0343\n",
      "Epoch 27: val_loss improved from 0.87025 to 0.82996, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6384 - loss: 1.0343 - val_accuracy: 0.7104 - val_loss: 0.8300 - learning_rate: 3.0000e-04\n",
      "Epoch 28/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6408 - loss: 1.0252\n",
      "Epoch 28: val_loss improved from 0.82996 to 0.80042, saving model to ../models/s3/model_trial_3_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6408 - loss: 1.0252 - val_accuracy: 0.7216 - val_loss: 0.8004 - learning_rate: 3.0000e-04\n",
      "Epoch 29/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6402 - loss: 1.0143\n",
      "Epoch 29: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6402 - loss: 1.0143 - val_accuracy: 0.6826 - val_loss: 0.9358 - learning_rate: 3.0000e-04\n",
      "Epoch 30/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6461 - loss: 1.0082\n",
      "Epoch 30: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6461 - loss: 1.0082 - val_accuracy: 0.6996 - val_loss: 0.8569 - learning_rate: 3.0000e-04\n",
      "Epoch 31/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6437 - loss: 1.0079\n",
      "Epoch 31: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6437 - loss: 1.0078 - val_accuracy: 0.6208 - val_loss: 1.1906 - learning_rate: 3.0000e-04\n",
      "Epoch 32/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6457 - loss: 0.9972\n",
      "Epoch 32: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6457 - loss: 0.9972 - val_accuracy: 0.6878 - val_loss: 0.9098 - learning_rate: 3.0000e-04\n",
      "Epoch 33/40\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6506 - loss: 0.9889\n",
      "Epoch 33: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6506 - loss: 0.9889 - val_accuracy: 0.6903 - val_loss: 0.8968 - learning_rate: 3.0000e-04\n",
      "Epoch 34/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6628 - loss: 0.9675\n",
      "Epoch 34: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6628 - loss: 0.9675 - val_accuracy: 0.7091 - val_loss: 0.8365 - learning_rate: 3.0000e-05\n",
      "Epoch 35/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6670 - loss: 0.9528\n",
      "Epoch 35: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6670 - loss: 0.9528 - val_accuracy: 0.7143 - val_loss: 0.8183 - learning_rate: 3.0000e-05\n",
      "Epoch 36/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6748 - loss: 0.9424\n",
      "Epoch 36: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6748 - loss: 0.9424 - val_accuracy: 0.6942 - val_loss: 0.8810 - learning_rate: 3.0000e-05\n",
      "Epoch 37/40\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6643 - loss: 0.9529\n",
      "Epoch 37: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6644 - loss: 0.9528 - val_accuracy: 0.6995 - val_loss: 0.8625 - learning_rate: 3.0000e-05\n",
      "Epoch 38/40\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6696 - loss: 0.9464\n",
      "Epoch 38: val_loss did not improve from 0.80042\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6696 - loss: 0.9463 - val_accuracy: 0.7113 - val_loss: 0.8292 - learning_rate: 3.0000e-05\n"
     ]
    }
   ],
   "source": [
    "model_path = '../models/s3/model_trial_1_DA_CPbest.keras'\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_loss',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "    ),    \n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.1,\n",
    "        patience=5,\n",
    "        min_lr=1e-5\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=40,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '1_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../plots/s3/trial_1_DA_plot.png)\n",
    "\n",
    "Como estamos a ter resultados semelhantes ao de sem data augmentation vamos tentar mais algumas épocas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 19:48:56.949704: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/sequential_15_1/dropout_49_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 33ms/step - accuracy: 0.6446 - loss: 1.0086 - val_accuracy: 0.6885 - val_loss: 0.8941 - learning_rate: 3.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6438 - loss: 1.0113 - val_accuracy: 0.6413 - val_loss: 1.0518 - learning_rate: 3.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6491 - loss: 0.9977 - val_accuracy: 0.7056 - val_loss: 0.8441 - learning_rate: 3.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6518 - loss: 0.9971 - val_accuracy: 0.7004 - val_loss: 0.8591 - learning_rate: 3.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6491 - loss: 0.9934 - val_accuracy: 0.7078 - val_loss: 0.8384 - learning_rate: 3.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6500 - loss: 0.9965 - val_accuracy: 0.6859 - val_loss: 0.8986 - learning_rate: 3.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6556 - loss: 0.9847 - val_accuracy: 0.6852 - val_loss: 0.9147 - learning_rate: 3.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6592 - loss: 0.9775 - val_accuracy: 0.7235 - val_loss: 0.8033 - learning_rate: 3.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6584 - loss: 0.9833 - val_accuracy: 0.6775 - val_loss: 0.9356 - learning_rate: 3.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6611 - loss: 0.9711 - val_accuracy: 0.7016 - val_loss: 0.8700 - learning_rate: 3.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6590 - loss: 0.9631 - val_accuracy: 0.7188 - val_loss: 0.8024 - learning_rate: 3.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6640 - loss: 0.9662 - val_accuracy: 0.7067 - val_loss: 0.8596 - learning_rate: 3.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6594 - loss: 0.9644 - val_accuracy: 0.7215 - val_loss: 0.7998 - learning_rate: 3.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6693 - loss: 0.9479 - val_accuracy: 0.7298 - val_loss: 0.7826 - learning_rate: 3.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6747 - loss: 0.9311 - val_accuracy: 0.7294 - val_loss: 0.7805 - learning_rate: 3.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6750 - loss: 0.9266 - val_accuracy: 0.7260 - val_loss: 0.7877 - learning_rate: 3.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6813 - loss: 0.9202 - val_accuracy: 0.7320 - val_loss: 0.7697 - learning_rate: 3.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6778 - loss: 0.9173 - val_accuracy: 0.7192 - val_loss: 0.8065 - learning_rate: 3.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6814 - loss: 0.9075 - val_accuracy: 0.7224 - val_loss: 0.7987 - learning_rate: 3.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6837 - loss: 0.9099 - val_accuracy: 0.7310 - val_loss: 0.7726 - learning_rate: 3.0000e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6842 - loss: 0.9069 - val_accuracy: 0.7252 - val_loss: 0.7838 - learning_rate: 3.0000e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6847 - loss: 0.9043 - val_accuracy: 0.7323 - val_loss: 0.7692 - learning_rate: 3.0000e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6836 - loss: 0.9077 - val_accuracy: 0.7300 - val_loss: 0.7708 - learning_rate: 3.0000e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6864 - loss: 0.8993 - val_accuracy: 0.7256 - val_loss: 0.7897 - learning_rate: 3.0000e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6853 - loss: 0.9015 - val_accuracy: 0.7103 - val_loss: 0.8317 - learning_rate: 3.0000e-05\n",
      "Epoch 26/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6886 - loss: 0.8984 - val_accuracy: 0.7195 - val_loss: 0.8033 - learning_rate: 3.0000e-05\n",
      "Epoch 27/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6867 - loss: 0.9023 - val_accuracy: 0.7386 - val_loss: 0.7556 - learning_rate: 3.0000e-05\n",
      "Epoch 28/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6857 - loss: 0.9038 - val_accuracy: 0.7235 - val_loss: 0.7973 - learning_rate: 3.0000e-05\n",
      "Epoch 29/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6921 - loss: 0.8917 - val_accuracy: 0.7280 - val_loss: 0.7759 - learning_rate: 3.0000e-05\n",
      "Epoch 30/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6889 - loss: 0.8939 - val_accuracy: 0.7253 - val_loss: 0.7812 - learning_rate: 3.0000e-05\n",
      "Epoch 31/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6862 - loss: 0.9038 - val_accuracy: 0.7261 - val_loss: 0.7823 - learning_rate: 3.0000e-05\n",
      "Epoch 32/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6833 - loss: 0.9041 - val_accuracy: 0.7291 - val_loss: 0.7779 - learning_rate: 3.0000e-05\n",
      "Epoch 33/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6840 - loss: 0.8918 - val_accuracy: 0.7272 - val_loss: 0.7833 - learning_rate: 3.0000e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6897 - loss: 0.8863 - val_accuracy: 0.7284 - val_loss: 0.7762 - learning_rate: 3.0000e-06\n",
      "Epoch 35/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6900 - loss: 0.8955 - val_accuracy: 0.7274 - val_loss: 0.7791 - learning_rate: 3.0000e-06\n",
      "Epoch 36/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6941 - loss: 0.8890 - val_accuracy: 0.7301 - val_loss: 0.7728 - learning_rate: 3.0000e-06\n",
      "Epoch 37/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6880 - loss: 0.8947 - val_accuracy: 0.7279 - val_loss: 0.7794 - learning_rate: 3.0000e-06\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('../models/s3/model_trial_1_DA_CPbest.keras')\n",
    "model_path = '../models/s3/model_trial_1_1_DA_CPbest.keras'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=10\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max',\n",
    "        factor=0.1,  \n",
    "        patience=5,  \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,  \n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '1_1_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../plots/s3/trial_1_1_DA_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificar resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - accuracy: 0.7345 - loss: 0.7642\n",
      "\tPrecião no conjunto de Teste: 0.7287\n",
      "\tPerda no conjunto de Teste:   0.7876\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o melhor modelo no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'\\tPrecião no conjunto de Teste: {test_acc:.4f}')\n",
    "print(f'\\tPerda no conjunto de Teste:   {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alterar data augmentation\n",
    "\n",
    "Como não estamos a conseguir melhores resultados vamos tentar aumentar um pouco mais as transformações aplicadas as imagens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "        layers.RandomContrast(0.1),\n",
    "        layers.RandomBrightness(0.1),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2\n",
    "No modelo aumentamos um pouco o learning rate para ver se conseguimos acelerar a convergência do treinamento e melhorar o desempenho do modelo. Este ajuste pode ajudar o modelo a aprender mais rapidamente. Embora possa não conseguir chegar a ajustes finos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patinhooh/miniconda3/envs/ia/lib/python3.11/site-packages/keras/src/layers/core/input_layer.py:25: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "num_filters_1 = 32\n",
    "num_filters_2 = 32\n",
    "num_filters_3 = 64\n",
    "optimizer_name = 'Adam'\n",
    "learning_rate = 5e-3\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# Primeira camada convolucional\n",
    "model.add(layers.Conv2D(num_filters_1, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model.add(layers.Conv2D(num_filters_2, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Segunda camada convolucional\n",
    "model.add(layers.Conv2D(num_filters_3, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Camadas flatten e dense\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = getattr(optimizers, optimizer_name)(learning_rate=learning_rate)\n",
    "\n",
    "model.compile(optimizer=optimizer,\n",
    "                loss='categorical_crossentropy',\n",
    "                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.3374 - loss: 1.8226 - val_accuracy: 0.3998 - val_loss: 1.6449 - learning_rate: 0.0050\n",
      "Epoch 2/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.4252 - loss: 1.6037 - val_accuracy: 0.4350 - val_loss: 1.6337 - learning_rate: 0.0050\n",
      "Epoch 3/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.4343 - loss: 1.5690 - val_accuracy: 0.5037 - val_loss: 1.3998 - learning_rate: 0.0050\n",
      "Epoch 4/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.4523 - loss: 1.5376 - val_accuracy: 0.5102 - val_loss: 1.3870 - learning_rate: 0.0050\n",
      "Epoch 5/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.4549 - loss: 1.5275 - val_accuracy: 0.5310 - val_loss: 1.3140 - learning_rate: 0.0050\n",
      "Epoch 6/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.4638 - loss: 1.5127 - val_accuracy: 0.5581 - val_loss: 1.2758 - learning_rate: 0.0050\n",
      "Epoch 7/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.4607 - loss: 1.5162 - val_accuracy: 0.5096 - val_loss: 1.4041 - learning_rate: 0.0050\n",
      "Epoch 8/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.4669 - loss: 1.5075 - val_accuracy: 0.5496 - val_loss: 1.2719 - learning_rate: 0.0050\n",
      "Epoch 9/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - accuracy: 0.4712 - loss: 1.5045 - val_accuracy: 0.4515 - val_loss: 1.8010 - learning_rate: 0.0050\n",
      "Epoch 10/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.4746 - loss: 1.4935 - val_accuracy: 0.5496 - val_loss: 1.2803 - learning_rate: 0.0050\n",
      "Epoch 11/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.4783 - loss: 1.4881 - val_accuracy: 0.5631 - val_loss: 1.2582 - learning_rate: 0.0050\n",
      "Epoch 12/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.4826 - loss: 1.4833 - val_accuracy: 0.5313 - val_loss: 1.3364 - learning_rate: 0.0050\n",
      "Epoch 13/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 34ms/step - accuracy: 0.4838 - loss: 1.4651 - val_accuracy: 0.4829 - val_loss: 1.4977 - learning_rate: 0.0050\n",
      "Epoch 14/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.4867 - loss: 1.4622 - val_accuracy: 0.5572 - val_loss: 1.3285 - learning_rate: 0.0050\n",
      "Epoch 15/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.4940 - loss: 1.4554 - val_accuracy: 0.5684 - val_loss: 1.2383 - learning_rate: 0.0050\n",
      "Epoch 16/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.4938 - loss: 1.4504 - val_accuracy: 0.5717 - val_loss: 1.3390 - learning_rate: 0.0050\n",
      "Epoch 17/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - accuracy: 0.4918 - loss: 1.4461 - val_accuracy: 0.5865 - val_loss: 1.1843 - learning_rate: 0.0050\n",
      "Epoch 18/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.4948 - loss: 1.4506 - val_accuracy: 0.5813 - val_loss: 1.2156 - learning_rate: 0.0050\n",
      "Epoch 19/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.4987 - loss: 1.4441 - val_accuracy: 0.5870 - val_loss: 1.1800 - learning_rate: 0.0050\n",
      "Epoch 20/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.4980 - loss: 1.4412 - val_accuracy: 0.3940 - val_loss: 2.1288 - learning_rate: 0.0050\n",
      "Epoch 21/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.5008 - loss: 1.4358 - val_accuracy: 0.5904 - val_loss: 1.1889 - learning_rate: 0.0050\n",
      "Epoch 22/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5022 - loss: 1.4355 - val_accuracy: 0.5812 - val_loss: 1.2223 - learning_rate: 0.0050\n",
      "Epoch 23/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5051 - loss: 1.4195 - val_accuracy: 0.4812 - val_loss: 1.7173 - learning_rate: 0.0050\n",
      "Epoch 24/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5032 - loss: 1.4219 - val_accuracy: 0.6289 - val_loss: 1.0829 - learning_rate: 0.0050\n",
      "Epoch 25/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5116 - loss: 1.4189 - val_accuracy: 0.5981 - val_loss: 1.1793 - learning_rate: 0.0050\n",
      "Epoch 26/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5083 - loss: 1.4145 - val_accuracy: 0.5621 - val_loss: 1.2476 - learning_rate: 0.0050\n",
      "Epoch 27/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5112 - loss: 1.4148 - val_accuracy: 0.5085 - val_loss: 1.4610 - learning_rate: 0.0050\n",
      "Epoch 28/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5068 - loss: 1.4224 - val_accuracy: 0.6119 - val_loss: 1.1274 - learning_rate: 0.0050\n",
      "Epoch 29/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5078 - loss: 1.4229 - val_accuracy: 0.5070 - val_loss: 1.5428 - learning_rate: 0.0050\n",
      "Epoch 30/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5148 - loss: 1.4031 - val_accuracy: 0.5872 - val_loss: 1.2814 - learning_rate: 0.0050\n",
      "Epoch 31/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5105 - loss: 1.4165 - val_accuracy: 0.5996 - val_loss: 1.1393 - learning_rate: 0.0050\n",
      "Epoch 32/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5147 - loss: 1.4067 - val_accuracy: 0.6193 - val_loss: 1.1077 - learning_rate: 0.0050\n",
      "Epoch 33/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5101 - loss: 1.4086 - val_accuracy: 0.6141 - val_loss: 1.1313 - learning_rate: 0.0050\n",
      "Epoch 34/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5143 - loss: 1.4047 - val_accuracy: 0.6173 - val_loss: 1.1067 - learning_rate: 0.0050\n",
      "Epoch 35/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5506 - loss: 1.2916 - val_accuracy: 0.6278 - val_loss: 1.0670 - learning_rate: 7.5000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5698 - loss: 1.2432 - val_accuracy: 0.6224 - val_loss: 1.0700 - learning_rate: 7.5000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5778 - loss: 1.2150 - val_accuracy: 0.6462 - val_loss: 1.0232 - learning_rate: 7.5000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5790 - loss: 1.2022 - val_accuracy: 0.6207 - val_loss: 1.0689 - learning_rate: 7.5000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5799 - loss: 1.2021 - val_accuracy: 0.6207 - val_loss: 1.0928 - learning_rate: 7.5000e-04\n",
      "Epoch 40/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5882 - loss: 1.1914 - val_accuracy: 0.6306 - val_loss: 1.0554 - learning_rate: 7.5000e-04\n",
      "Epoch 41/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5881 - loss: 1.1859 - val_accuracy: 0.6728 - val_loss: 0.9396 - learning_rate: 7.5000e-04\n",
      "Epoch 42/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5891 - loss: 1.1927 - val_accuracy: 0.6257 - val_loss: 1.0542 - learning_rate: 7.5000e-04\n",
      "Epoch 43/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5869 - loss: 1.1862 - val_accuracy: 0.6355 - val_loss: 1.0418 - learning_rate: 7.5000e-04\n",
      "Epoch 44/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.5933 - loss: 1.1690 - val_accuracy: 0.6535 - val_loss: 0.9950 - learning_rate: 7.5000e-04\n",
      "Epoch 45/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 36ms/step - accuracy: 0.5929 - loss: 1.1690 - val_accuracy: 0.6374 - val_loss: 1.0371 - learning_rate: 7.5000e-04\n",
      "Epoch 46/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.5909 - loss: 1.1739 - val_accuracy: 0.6576 - val_loss: 0.9859 - learning_rate: 7.5000e-04\n",
      "Epoch 47/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5948 - loss: 1.1671 - val_accuracy: 0.6298 - val_loss: 1.0561 - learning_rate: 7.5000e-04\n",
      "Epoch 48/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.5932 - loss: 1.1685 - val_accuracy: 0.6550 - val_loss: 1.0039 - learning_rate: 7.5000e-04\n",
      "Epoch 49/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6013 - loss: 1.1582 - val_accuracy: 0.6595 - val_loss: 0.9773 - learning_rate: 7.5000e-04\n",
      "Epoch 50/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5976 - loss: 1.1606 - val_accuracy: 0.6401 - val_loss: 1.0339 - learning_rate: 7.5000e-04\n",
      "Epoch 51/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5976 - loss: 1.1665 - val_accuracy: 0.6332 - val_loss: 1.0483 - learning_rate: 7.5000e-04\n",
      "Epoch 52/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5995 - loss: 1.1474 - val_accuracy: 0.6476 - val_loss: 1.0137 - learning_rate: 1.1250e-04\n",
      "Epoch 53/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6047 - loss: 1.1322 - val_accuracy: 0.6476 - val_loss: 1.0245 - learning_rate: 1.1250e-04\n",
      "Epoch 54/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6043 - loss: 1.1428 - val_accuracy: 0.6449 - val_loss: 1.0171 - learning_rate: 1.1250e-04\n",
      "Epoch 55/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6052 - loss: 1.1286 - val_accuracy: 0.6304 - val_loss: 1.0830 - learning_rate: 1.1250e-04\n",
      "Epoch 56/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6079 - loss: 1.1298 - val_accuracy: 0.6469 - val_loss: 1.0188 - learning_rate: 1.1250e-04\n"
     ]
    }
   ],
   "source": [
    "model_path = '../models/s3/model_trial_2_DA_CPbest.keras'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=15\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max',\n",
    "        factor=0.15,  \n",
    "        patience=10,  \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,  \n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '2_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../plots/s3/trial_2_DA_plot.png)\n",
    "\n",
    "Parece que o aumento do learning rate foi prejudicial ao modelo pois so aumentou a precisao quando o `ReduceLROnPlateau` foi ativo. Vamos ajustar os callbacks para tentar ajustar melhor o modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6041 - loss: 1.1360 - val_accuracy: 0.6465 - val_loss: 1.0351 - learning_rate: 1.1250e-04\n",
      "Epoch 2/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6109 - loss: 1.1268 - val_accuracy: 0.6436 - val_loss: 1.0394 - learning_rate: 1.1250e-04\n",
      "Epoch 3/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6084 - loss: 1.1274 - val_accuracy: 0.6357 - val_loss: 1.0618 - learning_rate: 1.1250e-04\n",
      "Epoch 4/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6066 - loss: 1.1255 - val_accuracy: 0.6474 - val_loss: 1.0188 - learning_rate: 1.1250e-04\n",
      "Epoch 5/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6078 - loss: 1.1216 - val_accuracy: 0.6478 - val_loss: 1.0276 - learning_rate: 1.1250e-04\n",
      "Epoch 6/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6075 - loss: 1.1243 - val_accuracy: 0.6480 - val_loss: 1.0305 - learning_rate: 1.1250e-04\n",
      "Epoch 7/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6125 - loss: 1.1216 - val_accuracy: 0.6515 - val_loss: 1.0155 - learning_rate: 1.1250e-04\n",
      "Epoch 8/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6069 - loss: 1.1239 - val_accuracy: 0.6512 - val_loss: 1.0044 - learning_rate: 1.1250e-04\n",
      "Epoch 9/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6081 - loss: 1.1241 - val_accuracy: 0.6443 - val_loss: 1.0282 - learning_rate: 1.1250e-04\n",
      "Epoch 10/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6117 - loss: 1.1241 - val_accuracy: 0.6433 - val_loss: 1.0391 - learning_rate: 1.1250e-04\n",
      "Epoch 11/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6073 - loss: 1.1186 - val_accuracy: 0.6425 - val_loss: 1.0452 - learning_rate: 1.1250e-04\n",
      "Epoch 12/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6096 - loss: 1.1207 - val_accuracy: 0.6444 - val_loss: 1.0281 - learning_rate: 1.1250e-04\n",
      "Epoch 13/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6131 - loss: 1.1135 - val_accuracy: 0.6504 - val_loss: 1.0131 - learning_rate: 2.2500e-05\n",
      "Epoch 14/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6036 - loss: 1.1318 - val_accuracy: 0.6466 - val_loss: 1.0255 - learning_rate: 2.2500e-05\n",
      "Epoch 15/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6092 - loss: 1.1147 - val_accuracy: 0.6478 - val_loss: 1.0185 - learning_rate: 2.2500e-05\n",
      "Epoch 16/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6105 - loss: 1.1170 - val_accuracy: 0.6467 - val_loss: 1.0279 - learning_rate: 2.2500e-05\n",
      "Epoch 17/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6101 - loss: 1.1192 - val_accuracy: 0.6503 - val_loss: 1.0115 - learning_rate: 2.2500e-05\n",
      "Epoch 18/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6086 - loss: 1.1179 - val_accuracy: 0.6507 - val_loss: 1.0157 - learning_rate: 4.5000e-06\n",
      "Epoch 19/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6101 - loss: 1.1190 - val_accuracy: 0.6503 - val_loss: 1.0173 - learning_rate: 4.5000e-06\n",
      "Epoch 20/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6145 - loss: 1.1197 - val_accuracy: 0.6486 - val_loss: 1.0217 - learning_rate: 4.5000e-06\n",
      "Epoch 21/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6122 - loss: 1.1109 - val_accuracy: 0.6501 - val_loss: 1.0164 - learning_rate: 4.5000e-06\n",
      "Epoch 22/44\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6086 - loss: 1.1183 - val_accuracy: 0.6486 - val_loss: 1.0220 - learning_rate: 4.5000e-06\n"
     ]
    }
   ],
   "source": [
    "model_path = '../models/s3/model_trial_2_1_DA_CPbest.keras'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=0\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=15\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max',\n",
    "        factor=0.2, # aumentado\n",
    "        patience=5,  # reduzido\n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=44,  # reduzido para chegar no maximo a 100 no total\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '2_1_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../plots/s3/trial_2_1_DA_plot.png)\n",
    "\n",
    "Aqui podemos ver que o modelo já estagnou ent vamos ter de mudar um pouco a estrutura pois esta está a ter dificultade em extrair filtros que consigam responder ao problema com muitos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo **3**\n",
    "Foram tentados alguns paramentros diferentes porem descartamos este modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo **4** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_34\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_34\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_79 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_76          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_58 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_99 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_80 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_77          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_59 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_100 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_81 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_78          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_101 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_102 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_27 (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_79 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_76          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_58 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_99 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_80 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_77          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_59 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_100 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_81 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_78          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_101 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_27 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_50 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_102 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,167,818</span> (4.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,167,818\u001b[0m (4.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,167,306</span> (4.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,167,306\u001b[0m (4.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> (2.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m512\u001b[0m (2.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_filters_1 = 64  # aumentado\n",
    "num_filters_2 = 64  # aumentado\n",
    "num_filters_3 = 128  # aumentado\n",
    "optimizer_name = 'Adam'\n",
    "learning_rate = 1e-3  # reduzido\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(layers.Conv2D(num_filters_1, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(num_filters_2, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(layers.Conv2D(num_filters_3, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Flatten and dense layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Optimizer and compilation\n",
    "optimizer = getattr(optimizers, optimizer_name)(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-20 23:24:43.696246: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/sequential_34_1/dropout_99_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3023 - loss: 2.4524\n",
      "Epoch 1: val_accuracy improved from -inf to 0.38450, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 32ms/step - accuracy: 0.3025 - loss: 2.4516 - val_accuracy: 0.3845 - val_loss: 1.7699 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4472 - loss: 1.5387\n",
      "Epoch 2: val_accuracy improved from 0.38450 to 0.52670, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.4472 - loss: 1.5387 - val_accuracy: 0.5267 - val_loss: 1.3493 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4891 - loss: 1.4325\n",
      "Epoch 3: val_accuracy did not improve from 0.52670\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.4891 - loss: 1.4325 - val_accuracy: 0.4755 - val_loss: 1.5830 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5121 - loss: 1.3843\n",
      "Epoch 4: val_accuracy improved from 0.52670 to 0.53810, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5121 - loss: 1.3842 - val_accuracy: 0.5381 - val_loss: 1.2929 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5287 - loss: 1.3274\n",
      "Epoch 5: val_accuracy improved from 0.53810 to 0.60460, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5287 - loss: 1.3273 - val_accuracy: 0.6046 - val_loss: 1.1113 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5526 - loss: 1.2648\n",
      "Epoch 6: val_accuracy improved from 0.60460 to 0.62140, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5526 - loss: 1.2648 - val_accuracy: 0.6214 - val_loss: 1.0829 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5737 - loss: 1.2157\n",
      "Epoch 7: val_accuracy improved from 0.62140 to 0.64090, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.5737 - loss: 1.2157 - val_accuracy: 0.6409 - val_loss: 1.0017 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5831 - loss: 1.1866\n",
      "Epoch 8: val_accuracy improved from 0.64090 to 0.65410, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5831 - loss: 1.1866 - val_accuracy: 0.6541 - val_loss: 0.9877 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5970 - loss: 1.1428\n",
      "Epoch 9: val_accuracy did not improve from 0.65410\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5970 - loss: 1.1428 - val_accuracy: 0.6526 - val_loss: 0.9889 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6141 - loss: 1.1076\n",
      "Epoch 10: val_accuracy improved from 0.65410 to 0.68640, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6141 - loss: 1.1076 - val_accuracy: 0.6864 - val_loss: 0.8999 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6222 - loss: 1.0832\n",
      "Epoch 11: val_accuracy did not improve from 0.68640\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6222 - loss: 1.0832 - val_accuracy: 0.6724 - val_loss: 0.9613 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6251 - loss: 1.0680\n",
      "Epoch 12: val_accuracy did not improve from 0.68640\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6251 - loss: 1.0680 - val_accuracy: 0.6719 - val_loss: 0.9547 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6444 - loss: 1.0269\n",
      "Epoch 13: val_accuracy improved from 0.68640 to 0.68810, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6444 - loss: 1.0269 - val_accuracy: 0.6881 - val_loss: 0.9103 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6455 - loss: 1.0171\n",
      "Epoch 14: val_accuracy improved from 0.68810 to 0.72170, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6455 - loss: 1.0171 - val_accuracy: 0.7217 - val_loss: 0.7856 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6526 - loss: 0.9983\n",
      "Epoch 15: val_accuracy did not improve from 0.72170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6526 - loss: 0.9983 - val_accuracy: 0.6486 - val_loss: 0.9886 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6582 - loss: 0.9895\n",
      "Epoch 16: val_accuracy did not improve from 0.72170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6582 - loss: 0.9895 - val_accuracy: 0.7140 - val_loss: 0.8226 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6606 - loss: 0.9750\n",
      "Epoch 17: val_accuracy did not improve from 0.72170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6606 - loss: 0.9750 - val_accuracy: 0.7154 - val_loss: 0.8080 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6684 - loss: 0.9624\n",
      "Epoch 18: val_accuracy did not improve from 0.72170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6684 - loss: 0.9624 - val_accuracy: 0.6777 - val_loss: 0.9515 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6660 - loss: 0.9564\n",
      "Epoch 19: val_accuracy did not improve from 0.72170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.6660 - loss: 0.9564 - val_accuracy: 0.6671 - val_loss: 0.9875 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6822 - loss: 0.9113\n",
      "Epoch 20: val_accuracy improved from 0.72170 to 0.73290, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6822 - loss: 0.9112 - val_accuracy: 0.7329 - val_loss: 0.7644 - learning_rate: 2.0000e-04\n",
      "Epoch 21/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6926 - loss: 0.8789\n",
      "Epoch 21: val_accuracy improved from 0.73290 to 0.73320, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6926 - loss: 0.8789 - val_accuracy: 0.7332 - val_loss: 0.7640 - learning_rate: 2.0000e-04\n",
      "Epoch 22/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7009 - loss: 0.8603\n",
      "Epoch 22: val_accuracy improved from 0.73320 to 0.73490, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7009 - loss: 0.8603 - val_accuracy: 0.7349 - val_loss: 0.7650 - learning_rate: 2.0000e-04\n",
      "Epoch 23/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7053 - loss: 0.8431\n",
      "Epoch 23: val_accuracy improved from 0.73490 to 0.74100, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7053 - loss: 0.8431 - val_accuracy: 0.7410 - val_loss: 0.7512 - learning_rate: 2.0000e-04\n",
      "Epoch 24/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7093 - loss: 0.8396\n",
      "Epoch 24: val_accuracy improved from 0.74100 to 0.74730, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.7094 - loss: 0.8396 - val_accuracy: 0.7473 - val_loss: 0.7355 - learning_rate: 2.0000e-04\n",
      "Epoch 25/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7119 - loss: 0.8260\n",
      "Epoch 25: val_accuracy did not improve from 0.74730\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7120 - loss: 0.8260 - val_accuracy: 0.7218 - val_loss: 0.8155 - learning_rate: 2.0000e-04\n",
      "Epoch 26/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7161 - loss: 0.8208\n",
      "Epoch 26: val_accuracy improved from 0.74730 to 0.75220, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7161 - loss: 0.8208 - val_accuracy: 0.7522 - val_loss: 0.7129 - learning_rate: 2.0000e-04\n",
      "Epoch 27/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7134 - loss: 0.8148\n",
      "Epoch 27: val_accuracy did not improve from 0.75220\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7134 - loss: 0.8148 - val_accuracy: 0.7488 - val_loss: 0.7297 - learning_rate: 2.0000e-04\n",
      "Epoch 28/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7156 - loss: 0.8167\n",
      "Epoch 28: val_accuracy improved from 0.75220 to 0.75410, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7156 - loss: 0.8167 - val_accuracy: 0.7541 - val_loss: 0.7017 - learning_rate: 2.0000e-04\n",
      "Epoch 29/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7150 - loss: 0.8162\n",
      "Epoch 29: val_accuracy improved from 0.75410 to 0.76030, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7150 - loss: 0.8162 - val_accuracy: 0.7603 - val_loss: 0.6930 - learning_rate: 2.0000e-04\n",
      "Epoch 30/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7163 - loss: 0.8112\n",
      "Epoch 30: val_accuracy did not improve from 0.76030\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7163 - loss: 0.8112 - val_accuracy: 0.7565 - val_loss: 0.7081 - learning_rate: 2.0000e-04\n",
      "Epoch 31/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7231 - loss: 0.8009\n",
      "Epoch 31: val_accuracy improved from 0.76030 to 0.76370, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7231 - loss: 0.8009 - val_accuracy: 0.7637 - val_loss: 0.6846 - learning_rate: 2.0000e-04\n",
      "Epoch 32/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7243 - loss: 0.7985\n",
      "Epoch 32: val_accuracy did not improve from 0.76370\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7243 - loss: 0.7985 - val_accuracy: 0.7479 - val_loss: 0.7311 - learning_rate: 2.0000e-04\n",
      "Epoch 33/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7238 - loss: 0.7876\n",
      "Epoch 33: val_accuracy improved from 0.76370 to 0.76470, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7238 - loss: 0.7876 - val_accuracy: 0.7647 - val_loss: 0.6915 - learning_rate: 2.0000e-04\n",
      "Epoch 34/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7252 - loss: 0.7893\n",
      "Epoch 34: val_accuracy did not improve from 0.76470\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7252 - loss: 0.7893 - val_accuracy: 0.7631 - val_loss: 0.6957 - learning_rate: 2.0000e-04\n",
      "Epoch 35/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7260 - loss: 0.7866\n",
      "Epoch 35: val_accuracy did not improve from 0.76470\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7260 - loss: 0.7866 - val_accuracy: 0.7491 - val_loss: 0.7310 - learning_rate: 2.0000e-04\n",
      "Epoch 36/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7305 - loss: 0.7856\n",
      "Epoch 36: val_accuracy did not improve from 0.76470\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7305 - loss: 0.7856 - val_accuracy: 0.7496 - val_loss: 0.7263 - learning_rate: 2.0000e-04\n",
      "Epoch 37/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7263 - loss: 0.7836\n",
      "Epoch 37: val_accuracy did not improve from 0.76470\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7263 - loss: 0.7836 - val_accuracy: 0.7599 - val_loss: 0.6864 - learning_rate: 2.0000e-04\n",
      "Epoch 38/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7285 - loss: 0.7802\n",
      "Epoch 38: val_accuracy did not improve from 0.76470\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7285 - loss: 0.7801 - val_accuracy: 0.7605 - val_loss: 0.6986 - learning_rate: 2.0000e-04\n",
      "Epoch 39/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7296 - loss: 0.7699\n",
      "Epoch 39: val_accuracy improved from 0.76470 to 0.77360, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7296 - loss: 0.7699 - val_accuracy: 0.7736 - val_loss: 0.6513 - learning_rate: 4.0000e-05\n",
      "Epoch 40/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7342 - loss: 0.7634\n",
      "Epoch 40: val_accuracy did not improve from 0.77360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7342 - loss: 0.7634 - val_accuracy: 0.7609 - val_loss: 0.6902 - learning_rate: 4.0000e-05\n",
      "Epoch 41/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7375 - loss: 0.7574\n",
      "Epoch 41: val_accuracy did not improve from 0.77360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7375 - loss: 0.7574 - val_accuracy: 0.7597 - val_loss: 0.6949 - learning_rate: 4.0000e-05\n",
      "Epoch 42/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7372 - loss: 0.7518\n",
      "Epoch 42: val_accuracy did not improve from 0.77360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7372 - loss: 0.7518 - val_accuracy: 0.7712 - val_loss: 0.6556 - learning_rate: 4.0000e-05\n",
      "Epoch 43/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7332 - loss: 0.7630\n",
      "Epoch 43: val_accuracy improved from 0.77360 to 0.77560, saving model to ../models/s3/model_trial_3_3_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7332 - loss: 0.7630 - val_accuracy: 0.7756 - val_loss: 0.6466 - learning_rate: 4.0000e-05\n",
      "Epoch 44/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7340 - loss: 0.7625\n",
      "Epoch 44: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7340 - loss: 0.7625 - val_accuracy: 0.7733 - val_loss: 0.6565 - learning_rate: 4.0000e-05\n",
      "Epoch 45/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7334 - loss: 0.7571\n",
      "Epoch 45: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7334 - loss: 0.7571 - val_accuracy: 0.7679 - val_loss: 0.6697 - learning_rate: 4.0000e-05\n",
      "Epoch 46/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7365 - loss: 0.7575\n",
      "Epoch 46: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7365 - loss: 0.7575 - val_accuracy: 0.7712 - val_loss: 0.6547 - learning_rate: 4.0000e-05\n",
      "Epoch 47/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7380 - loss: 0.7559\n",
      "Epoch 47: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7380 - loss: 0.7559 - val_accuracy: 0.7730 - val_loss: 0.6526 - learning_rate: 4.0000e-05\n",
      "Epoch 48/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7367 - loss: 0.7530\n",
      "Epoch 48: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7367 - loss: 0.7529 - val_accuracy: 0.7722 - val_loss: 0.6561 - learning_rate: 4.0000e-05\n",
      "Epoch 49/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7392 - loss: 0.7480\n",
      "Epoch 49: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7392 - loss: 0.7480 - val_accuracy: 0.7712 - val_loss: 0.6589 - learning_rate: 8.0000e-06\n",
      "Epoch 50/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7367 - loss: 0.7499\n",
      "Epoch 50: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7367 - loss: 0.7499 - val_accuracy: 0.7724 - val_loss: 0.6569 - learning_rate: 8.0000e-06\n",
      "Epoch 51/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7348 - loss: 0.7555\n",
      "Epoch 51: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7348 - loss: 0.7555 - val_accuracy: 0.7718 - val_loss: 0.6588 - learning_rate: 8.0000e-06\n",
      "Epoch 52/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7377 - loss: 0.7513\n",
      "Epoch 52: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7377 - loss: 0.7513 - val_accuracy: 0.7701 - val_loss: 0.6624 - learning_rate: 8.0000e-06\n",
      "Epoch 53/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7356 - loss: 0.7561\n",
      "Epoch 53: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.7356 - loss: 0.7561 - val_accuracy: 0.7716 - val_loss: 0.6580 - learning_rate: 8.0000e-06\n",
      "Epoch 54/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7377 - loss: 0.7573\n",
      "Epoch 54: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7377 - loss: 0.7573 - val_accuracy: 0.7716 - val_loss: 0.6576 - learning_rate: 1.6000e-06\n",
      "Epoch 55/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7393 - loss: 0.7486\n",
      "Epoch 55: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7393 - loss: 0.7485 - val_accuracy: 0.7716 - val_loss: 0.6586 - learning_rate: 1.6000e-06\n",
      "Epoch 56/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7352 - loss: 0.7477\n",
      "Epoch 56: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7352 - loss: 0.7477 - val_accuracy: 0.7705 - val_loss: 0.6593 - learning_rate: 1.6000e-06\n",
      "Epoch 57/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7389 - loss: 0.7466\n",
      "Epoch 57: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7389 - loss: 0.7466 - val_accuracy: 0.7705 - val_loss: 0.6593 - learning_rate: 1.6000e-06\n",
      "Epoch 58/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7392 - loss: 0.7509\n",
      "Epoch 58: val_accuracy did not improve from 0.77560\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 35ms/step - accuracy: 0.7392 - loss: 0.7509 - val_accuracy: 0.7706 - val_loss: 0.6615 - learning_rate: 1.6000e-06\n"
     ]
    }
   ],
   "source": [
    "model_path = '../models/s3/model_trial_4_DA_CPbest.keras'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=15\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max',\n",
    "        factor=0.2,  \n",
    "        patience=5,  \n",
    "        min_lr=1e-6\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,  \n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '4_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo 4\n",
    "\n",
    "![](../plots/s3/trial_4_DA_plot.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.7722 - loss: 0.6577\n",
      "\tPrecião no conjunto de Teste: 0.7636\n",
      "\tPerda no conjunto de Teste:   0.6844\n"
     ]
    }
   ],
   "source": [
    "# Avaliar o melhor modelo no conjunto de teste\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'\\tPrecião no conjunto de Teste: {test_acc:.4f}')\n",
    "print(f'\\tPerda no conjunto de Teste:   {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos no caminho certo, agr o modelo ja esta a chegar valores melhores que ao modelo sem data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo **5**\n",
    "Neste modelo tentamos recuperar o que tinhamos constatado anteriormente, a melhor performance quando a primeira camada é composta por 32 filtros e aumentar os restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_42\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_42\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_103 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_100         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_74 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_131 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_104 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,992</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_101         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_75 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_132 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_105 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_102         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_133 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_134 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,130</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ sequential_27 (\u001b[38;5;33mSequential\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_103 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_100         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_74 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_131 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_104 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m36,992\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_101         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_75 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_132 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_105 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_102         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_133 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_35 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_66 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,097,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_134 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_67 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m5,130\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,437,514</span> (9.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,437,514\u001b[0m (9.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,436,682</span> (9.30 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,436,682\u001b[0m (9.30 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> (3.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m832\u001b[0m (3.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_filters_1 = 32 # reduzido\n",
    "num_filters_2 = 128  # aumentado\n",
    "num_filters_3 = 256 # aumentado\n",
    "optimizer_name = 'Adam'\n",
    "learning_rate = 1e-3 \n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.InputLayer(input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# First convolutional layer\n",
    "model.add(layers.Conv2D(num_filters_1, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Second convolutional layer\n",
    "model.add(layers.Conv2D(num_filters_2, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Third convolutional layer\n",
    "model.add(layers.Conv2D(num_filters_3, (3, 3), activation='relu'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Dropout(0.3))\n",
    "\n",
    "# Flatten and dense layers\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Optimizer and compilation\n",
    "optimizer = getattr(optimizers, optimizer_name)(learning_rate=learning_rate)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 00:38:08.085395: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/sequential_42_1/dropout_131_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3179 - loss: 2.6240\n",
      "Epoch 1: val_accuracy improved from -inf to 0.46760, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 31ms/step - accuracy: 0.3179 - loss: 2.6235 - val_accuracy: 0.4676 - val_loss: 1.6311 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4530 - loss: 1.5346\n",
      "Epoch 2: val_accuracy improved from 0.46760 to 0.51350, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4530 - loss: 1.5345 - val_accuracy: 0.5135 - val_loss: 1.9040 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.4876 - loss: 1.4496\n",
      "Epoch 3: val_accuracy did not improve from 0.51350\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.4876 - loss: 1.4496 - val_accuracy: 0.4829 - val_loss: 1.5753 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5028 - loss: 1.4061\n",
      "Epoch 4: val_accuracy improved from 0.51350 to 0.54500, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5028 - loss: 1.4060 - val_accuracy: 0.5450 - val_loss: 1.5774 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5226 - loss: 1.3503\n",
      "Epoch 5: val_accuracy did not improve from 0.54500\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.5226 - loss: 1.3502 - val_accuracy: 0.4405 - val_loss: 3.1667 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5431 - loss: 1.3013\n",
      "Epoch 6: val_accuracy improved from 0.54500 to 0.59600, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5431 - loss: 1.3013 - val_accuracy: 0.5960 - val_loss: 1.2196 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5549 - loss: 1.2740\n",
      "Epoch 7: val_accuracy did not improve from 0.59600\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5550 - loss: 1.2740 - val_accuracy: 0.5547 - val_loss: 1.3920 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5781 - loss: 1.2199\n",
      "Epoch 8: val_accuracy did not improve from 0.59600\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.5781 - loss: 1.2198 - val_accuracy: 0.5837 - val_loss: 1.3612 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5924 - loss: 1.1872\n",
      "Epoch 9: val_accuracy improved from 0.59600 to 0.66770, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.5924 - loss: 1.1872 - val_accuracy: 0.6677 - val_loss: 0.9662 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6014 - loss: 1.1524\n",
      "Epoch 10: val_accuracy did not improve from 0.66770\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6014 - loss: 1.1524 - val_accuracy: 0.6563 - val_loss: 0.9928 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6114 - loss: 1.1133\n",
      "Epoch 11: val_accuracy did not improve from 0.66770\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6114 - loss: 1.1133 - val_accuracy: 0.6145 - val_loss: 1.1248 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6156 - loss: 1.0974\n",
      "Epoch 12: val_accuracy improved from 0.66770 to 0.71340, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6156 - loss: 1.0974 - val_accuracy: 0.7134 - val_loss: 0.8260 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6284 - loss: 1.0663\n",
      "Epoch 13: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6284 - loss: 1.0663 - val_accuracy: 0.6906 - val_loss: 0.8992 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6418 - loss: 1.0380\n",
      "Epoch 14: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6418 - loss: 1.0380 - val_accuracy: 0.6851 - val_loss: 0.9229 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.6473 - loss: 1.0268\n",
      "Epoch 15: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.6473 - loss: 1.0268 - val_accuracy: 0.7058 - val_loss: 0.8752 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6501 - loss: 1.0147\n",
      "Epoch 16: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6501 - loss: 1.0147 - val_accuracy: 0.7121 - val_loss: 0.8224 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6578 - loss: 0.9875\n",
      "Epoch 17: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 34ms/step - accuracy: 0.6578 - loss: 0.9875 - val_accuracy: 0.6952 - val_loss: 0.8802 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6704 - loss: 0.9648\n",
      "Epoch 18: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.6704 - loss: 0.9648 - val_accuracy: 0.6632 - val_loss: 1.0099 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6706 - loss: 0.9479\n",
      "Epoch 19: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6706 - loss: 0.9479 - val_accuracy: 0.7041 - val_loss: 0.8790 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6755 - loss: 0.9371\n",
      "Epoch 20: val_accuracy did not improve from 0.71340\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.6755 - loss: 0.9371 - val_accuracy: 0.7113 - val_loss: 0.8615 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6792 - loss: 0.9309\n",
      "Epoch 21: val_accuracy improved from 0.71340 to 0.72830, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6792 - loss: 0.9309 - val_accuracy: 0.7283 - val_loss: 0.7781 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6818 - loss: 0.9191\n",
      "Epoch 22: val_accuracy did not improve from 0.72830\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6818 - loss: 0.9190 - val_accuracy: 0.7254 - val_loss: 0.8424 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6861 - loss: 0.8988\n",
      "Epoch 23: val_accuracy improved from 0.72830 to 0.73300, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6861 - loss: 0.8988 - val_accuracy: 0.7330 - val_loss: 0.7741 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6886 - loss: 0.9033\n",
      "Epoch 24: val_accuracy improved from 0.73300 to 0.75320, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.6886 - loss: 0.9033 - val_accuracy: 0.7532 - val_loss: 0.7350 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6962 - loss: 0.8877\n",
      "Epoch 25: val_accuracy did not improve from 0.75320\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6962 - loss: 0.8877 - val_accuracy: 0.7141 - val_loss: 0.8807 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6979 - loss: 0.8773\n",
      "Epoch 26: val_accuracy did not improve from 0.75320\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6979 - loss: 0.8773 - val_accuracy: 0.7282 - val_loss: 0.8005 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.6981 - loss: 0.8689\n",
      "Epoch 27: val_accuracy did not improve from 0.75320\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.6981 - loss: 0.8689 - val_accuracy: 0.7363 - val_loss: 0.8112 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7052 - loss: 0.8526\n",
      "Epoch 28: val_accuracy improved from 0.75320 to 0.76150, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7052 - loss: 0.8526 - val_accuracy: 0.7615 - val_loss: 0.7258 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7063 - loss: 0.8587\n",
      "Epoch 29: val_accuracy did not improve from 0.76150\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7063 - loss: 0.8587 - val_accuracy: 0.7379 - val_loss: 0.7872 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7054 - loss: 0.8493\n",
      "Epoch 30: val_accuracy did not improve from 0.76150\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7054 - loss: 0.8493 - val_accuracy: 0.7598 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7075 - loss: 0.8426\n",
      "Epoch 31: val_accuracy did not improve from 0.76150\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7076 - loss: 0.8426 - val_accuracy: 0.7467 - val_loss: 0.7791 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7064 - loss: 0.8414\n",
      "Epoch 32: val_accuracy did not improve from 0.76150\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7064 - loss: 0.8414 - val_accuracy: 0.7600 - val_loss: 0.7163 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7147 - loss: 0.8251\n",
      "Epoch 33: val_accuracy did not improve from 0.76150\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7147 - loss: 0.8251 - val_accuracy: 0.7397 - val_loss: 0.7928 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7145 - loss: 0.8287\n",
      "Epoch 34: val_accuracy improved from 0.76150 to 0.76390, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7145 - loss: 0.8286 - val_accuracy: 0.7639 - val_loss: 0.7000 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7220 - loss: 0.8168\n",
      "Epoch 35: val_accuracy did not improve from 0.76390\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7220 - loss: 0.8168 - val_accuracy: 0.7376 - val_loss: 0.8196 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7214 - loss: 0.8053\n",
      "Epoch 36: val_accuracy improved from 0.76390 to 0.77160, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7214 - loss: 0.8053 - val_accuracy: 0.7716 - val_loss: 0.6723 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7219 - loss: 0.8091\n",
      "Epoch 37: val_accuracy did not improve from 0.77160\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7219 - loss: 0.8091 - val_accuracy: 0.7628 - val_loss: 0.7097 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7208 - loss: 0.8020\n",
      "Epoch 38: val_accuracy did not improve from 0.77160\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7208 - loss: 0.8020 - val_accuracy: 0.7556 - val_loss: 0.7647 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7245 - loss: 0.8015\n",
      "Epoch 39: val_accuracy did not improve from 0.77160\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7245 - loss: 0.8015 - val_accuracy: 0.7184 - val_loss: 0.8958 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7289 - loss: 0.7852\n",
      "Epoch 40: val_accuracy did not improve from 0.77160\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7289 - loss: 0.7852 - val_accuracy: 0.6900 - val_loss: 1.0916 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7313 - loss: 0.7816\n",
      "Epoch 41: val_accuracy did not improve from 0.77160\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7313 - loss: 0.7816 - val_accuracy: 0.7701 - val_loss: 0.7238 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7334 - loss: 0.7825\n",
      "Epoch 42: val_accuracy did not improve from 0.77160\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7334 - loss: 0.7825 - val_accuracy: 0.7653 - val_loss: 0.7256 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7282 - loss: 0.7804\n",
      "Epoch 43: val_accuracy improved from 0.77160 to 0.78200, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7282 - loss: 0.7804 - val_accuracy: 0.7820 - val_loss: 0.6455 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7294 - loss: 0.7802\n",
      "Epoch 44: val_accuracy improved from 0.78200 to 0.78360, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7294 - loss: 0.7802 - val_accuracy: 0.7836 - val_loss: 0.6568 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7416 - loss: 0.7673\n",
      "Epoch 45: val_accuracy did not improve from 0.78360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7416 - loss: 0.7673 - val_accuracy: 0.7823 - val_loss: 0.6494 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7332 - loss: 0.7739\n",
      "Epoch 46: val_accuracy did not improve from 0.78360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7332 - loss: 0.7739 - val_accuracy: 0.7624 - val_loss: 0.7261 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7356 - loss: 0.7666\n",
      "Epoch 47: val_accuracy did not improve from 0.78360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7356 - loss: 0.7666 - val_accuracy: 0.7632 - val_loss: 0.7195 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7379 - loss: 0.7613\n",
      "Epoch 48: val_accuracy did not improve from 0.78360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7379 - loss: 0.7612 - val_accuracy: 0.7799 - val_loss: 0.6569 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7410 - loss: 0.7566\n",
      "Epoch 49: val_accuracy did not improve from 0.78360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 32ms/step - accuracy: 0.7410 - loss: 0.7565 - val_accuracy: 0.7028 - val_loss: 1.0972 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.7370 - loss: 0.7630\n",
      "Epoch 50: val_accuracy did not improve from 0.78360\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 41ms/step - accuracy: 0.7371 - loss: 0.7630 - val_accuracy: 0.7651 - val_loss: 0.7239 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7441 - loss: 0.7451\n",
      "Epoch 51: val_accuracy improved from 0.78360 to 0.78520, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 40ms/step - accuracy: 0.7441 - loss: 0.7451 - val_accuracy: 0.7852 - val_loss: 0.6676 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7488 - loss: 0.7402\n",
      "Epoch 52: val_accuracy did not improve from 0.78520\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7488 - loss: 0.7402 - val_accuracy: 0.7355 - val_loss: 0.9581 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7431 - loss: 0.7496\n",
      "Epoch 53: val_accuracy improved from 0.78520 to 0.79090, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7431 - loss: 0.7495 - val_accuracy: 0.7909 - val_loss: 0.6565 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7483 - loss: 0.7313\n",
      "Epoch 54: val_accuracy did not improve from 0.79090\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7483 - loss: 0.7313 - val_accuracy: 0.7851 - val_loss: 0.6848 - learning_rate: 0.0010\n",
      "Epoch 55/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7445 - loss: 0.7365\n",
      "Epoch 55: val_accuracy did not improve from 0.79090\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7445 - loss: 0.7365 - val_accuracy: 0.7569 - val_loss: 0.7883 - learning_rate: 0.0010\n",
      "Epoch 56/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7455 - loss: 0.7397\n",
      "Epoch 56: val_accuracy improved from 0.79090 to 0.79620, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7455 - loss: 0.7397 - val_accuracy: 0.7962 - val_loss: 0.6192 - learning_rate: 0.0010\n",
      "Epoch 57/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7459 - loss: 0.7340\n",
      "Epoch 57: val_accuracy did not improve from 0.79620\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7459 - loss: 0.7340 - val_accuracy: 0.7874 - val_loss: 0.6615 - learning_rate: 0.0010\n",
      "Epoch 58/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7508 - loss: 0.7287\n",
      "Epoch 58: val_accuracy did not improve from 0.79620\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7508 - loss: 0.7287 - val_accuracy: 0.7620 - val_loss: 0.7552 - learning_rate: 0.0010\n",
      "Epoch 59/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7536 - loss: 0.7193\n",
      "Epoch 59: val_accuracy did not improve from 0.79620\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7536 - loss: 0.7193 - val_accuracy: 0.7676 - val_loss: 0.7347 - learning_rate: 0.0010\n",
      "Epoch 60/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7482 - loss: 0.7369\n",
      "Epoch 60: val_accuracy did not improve from 0.79620\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.7482 - loss: 0.7368 - val_accuracy: 0.7784 - val_loss: 0.6939 - learning_rate: 0.0010\n",
      "Epoch 61/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7514 - loss: 0.7245\n",
      "Epoch 61: val_accuracy improved from 0.79620 to 0.79890, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7514 - loss: 0.7245 - val_accuracy: 0.7989 - val_loss: 0.6086 - learning_rate: 0.0010\n",
      "Epoch 62/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7487 - loss: 0.7254\n",
      "Epoch 62: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7487 - loss: 0.7254 - val_accuracy: 0.7876 - val_loss: 0.6852 - learning_rate: 0.0010\n",
      "Epoch 63/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7547 - loss: 0.7183\n",
      "Epoch 63: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7547 - loss: 0.7183 - val_accuracy: 0.7954 - val_loss: 0.6167 - learning_rate: 0.0010\n",
      "Epoch 64/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7499 - loss: 0.7285\n",
      "Epoch 64: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7499 - loss: 0.7284 - val_accuracy: 0.7793 - val_loss: 0.6570 - learning_rate: 0.0010\n",
      "Epoch 65/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7544 - loss: 0.7097\n",
      "Epoch 65: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7544 - loss: 0.7097 - val_accuracy: 0.7738 - val_loss: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 66/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7514 - loss: 0.7237\n",
      "Epoch 66: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7514 - loss: 0.7236 - val_accuracy: 0.7804 - val_loss: 0.7114 - learning_rate: 0.0010\n",
      "Epoch 67/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7564 - loss: 0.7082\n",
      "Epoch 67: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7564 - loss: 0.7082 - val_accuracy: 0.7749 - val_loss: 0.7569 - learning_rate: 0.0010\n",
      "Epoch 68/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7558 - loss: 0.7099\n",
      "Epoch 68: val_accuracy did not improve from 0.79890\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7558 - loss: 0.7099 - val_accuracy: 0.7791 - val_loss: 0.6969 - learning_rate: 0.0010\n",
      "Epoch 69/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7534 - loss: 0.7095\n",
      "Epoch 69: val_accuracy improved from 0.79890 to 0.80170, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7534 - loss: 0.7095 - val_accuracy: 0.8017 - val_loss: 0.6157 - learning_rate: 0.0010\n",
      "Epoch 70/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7570 - loss: 0.7055\n",
      "Epoch 70: val_accuracy did not improve from 0.80170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 34ms/step - accuracy: 0.7570 - loss: 0.7055 - val_accuracy: 0.7861 - val_loss: 0.6446 - learning_rate: 0.0010\n",
      "Epoch 71/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.7571 - loss: 0.6992\n",
      "Epoch 71: val_accuracy did not improve from 0.80170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 35ms/step - accuracy: 0.7571 - loss: 0.6991 - val_accuracy: 0.7757 - val_loss: 0.7242 - learning_rate: 0.0010\n",
      "Epoch 72/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7614 - loss: 0.6991\n",
      "Epoch 72: val_accuracy did not improve from 0.80170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7614 - loss: 0.6991 - val_accuracy: 0.7696 - val_loss: 0.7334 - learning_rate: 0.0010\n",
      "Epoch 73/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7573 - loss: 0.7005\n",
      "Epoch 73: val_accuracy did not improve from 0.80170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7573 - loss: 0.7005 - val_accuracy: 0.7507 - val_loss: 0.8049 - learning_rate: 0.0010\n",
      "Epoch 74/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7617 - loss: 0.6971\n",
      "Epoch 74: val_accuracy did not improve from 0.80170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7617 - loss: 0.6971 - val_accuracy: 0.7911 - val_loss: 0.6228 - learning_rate: 0.0010\n",
      "Epoch 75/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7608 - loss: 0.6929\n",
      "Epoch 75: val_accuracy did not improve from 0.80170\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.7608 - loss: 0.6929 - val_accuracy: 0.7798 - val_loss: 0.6821 - learning_rate: 0.0010\n",
      "Epoch 76/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7636 - loss: 0.6966\n",
      "Epoch 76: val_accuracy improved from 0.80170 to 0.80480, saving model to ../models/s3/model_trial_3_4_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 33ms/step - accuracy: 0.7636 - loss: 0.6966 - val_accuracy: 0.8048 - val_loss: 0.6015 - learning_rate: 0.0010\n",
      "Epoch 77/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7629 - loss: 0.7003\n",
      "Epoch 77: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7629 - loss: 0.7003 - val_accuracy: 0.7838 - val_loss: 0.6928 - learning_rate: 0.0010\n",
      "Epoch 78/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7626 - loss: 0.6895\n",
      "Epoch 78: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.7626 - loss: 0.6895 - val_accuracy: 0.7553 - val_loss: 0.7756 - learning_rate: 0.0010\n",
      "Epoch 79/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7623 - loss: 0.6939\n",
      "Epoch 79: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7623 - loss: 0.6939 - val_accuracy: 0.8036 - val_loss: 0.6006 - learning_rate: 0.0010\n",
      "Epoch 80/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7603 - loss: 0.7018\n",
      "Epoch 80: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7603 - loss: 0.7018 - val_accuracy: 0.7760 - val_loss: 0.6964 - learning_rate: 0.0010\n",
      "Epoch 81/100\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7621 - loss: 0.6907\n",
      "Epoch 81: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7622 - loss: 0.6907 - val_accuracy: 0.7797 - val_loss: 0.7153 - learning_rate: 0.0010\n",
      "Epoch 82/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7676 - loss: 0.6775\n",
      "Epoch 82: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7676 - loss: 0.6775 - val_accuracy: 0.7712 - val_loss: 0.7229 - learning_rate: 0.0010\n",
      "Epoch 83/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7675 - loss: 0.6747\n",
      "Epoch 83: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 32ms/step - accuracy: 0.7675 - loss: 0.6747 - val_accuracy: 0.7704 - val_loss: 0.7238 - learning_rate: 0.0010\n",
      "Epoch 84/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7690 - loss: 0.6793\n",
      "Epoch 84: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 33ms/step - accuracy: 0.7690 - loss: 0.6793 - val_accuracy: 0.8035 - val_loss: 0.6060 - learning_rate: 0.0010\n",
      "Epoch 85/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7665 - loss: 0.6725\n",
      "Epoch 85: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 32ms/step - accuracy: 0.7665 - loss: 0.6725 - val_accuracy: 0.7970 - val_loss: 0.6439 - learning_rate: 0.0010\n",
      "Epoch 86/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7632 - loss: 0.6865\n",
      "Epoch 86: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7632 - loss: 0.6865 - val_accuracy: 0.7546 - val_loss: 0.8826 - learning_rate: 0.0010\n",
      "Epoch 87/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7753 - loss: 0.6531\n",
      "Epoch 87: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7753 - loss: 0.6531 - val_accuracy: 0.8002 - val_loss: 0.6510 - learning_rate: 5.0000e-05\n",
      "Epoch 88/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7909 - loss: 0.6167\n",
      "Epoch 88: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7909 - loss: 0.6167 - val_accuracy: 0.8041 - val_loss: 0.6332 - learning_rate: 5.0000e-05\n",
      "Epoch 89/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7902 - loss: 0.6094\n",
      "Epoch 89: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7902 - loss: 0.6094 - val_accuracy: 0.8021 - val_loss: 0.6404 - learning_rate: 5.0000e-05\n",
      "Epoch 90/100\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7951 - loss: 0.5994\n",
      "Epoch 90: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7951 - loss: 0.5994 - val_accuracy: 0.8027 - val_loss: 0.6355 - learning_rate: 5.0000e-05\n",
      "Epoch 91/100\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7958 - loss: 0.5906\n",
      "Epoch 91: val_accuracy did not improve from 0.80480\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7958 - loss: 0.5906 - val_accuracy: 0.8029 - val_loss: 0.6280 - learning_rate: 5.0000e-05\n"
     ]
    }
   ],
   "source": [
    "model_path = '../models/s3/model_trial_5_DA_CPbest.keras'\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=15\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max',\n",
    "        factor=0.05,  \n",
    "        patience=10,  \n",
    "        min_lr=1e-5\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,  \n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '5_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../plots/s3/trial_5_DA_plot.png)\n",
    "\n",
    "\n",
    "Como o modelo subiu um degrau com o diminuir do learning rate então vamos tentar treinar mais umas épocas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-21 01:40:23.246522: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inStatefulPartitionedCall/sequential_42_1/dropout_131_1/stateless_dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7597 - loss: 0.6974\n",
      "Epoch 1: val_accuracy improved from -inf to 0.79270, saving model to ../models/s3/model_trial_3_4_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 29ms/step - accuracy: 0.7597 - loss: 0.6974 - val_accuracy: 0.7927 - val_loss: 0.6381 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7650 - loss: 0.6904\n",
      "Epoch 2: val_accuracy did not improve from 0.79270\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 29ms/step - accuracy: 0.7650 - loss: 0.6904 - val_accuracy: 0.7917 - val_loss: 0.6465 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7647 - loss: 0.6902\n",
      "Epoch 3: val_accuracy improved from 0.79270 to 0.80230, saving model to ../models/s3/model_trial_3_4_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7647 - loss: 0.6902 - val_accuracy: 0.8023 - val_loss: 0.6264 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7642 - loss: 0.6841\n",
      "Epoch 4: val_accuracy did not improve from 0.80230\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7642 - loss: 0.6841 - val_accuracy: 0.7679 - val_loss: 0.7534 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7635 - loss: 0.6954\n",
      "Epoch 5: val_accuracy did not improve from 0.80230\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7635 - loss: 0.6954 - val_accuracy: 0.7920 - val_loss: 0.6605 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7648 - loss: 0.6753\n",
      "Epoch 6: val_accuracy did not improve from 0.80230\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7648 - loss: 0.6753 - val_accuracy: 0.8001 - val_loss: 0.6115 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7738 - loss: 0.6520\n",
      "Epoch 7: val_accuracy did not improve from 0.80230\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 29ms/step - accuracy: 0.7738 - loss: 0.6520 - val_accuracy: 0.7955 - val_loss: 0.6669 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7827 - loss: 0.6238\n",
      "Epoch 8: val_accuracy improved from 0.80230 to 0.80600, saving model to ../models/s3/model_trial_3_4_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7827 - loss: 0.6237 - val_accuracy: 0.8060 - val_loss: 0.6142 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7887 - loss: 0.6140\n",
      "Epoch 9: val_accuracy did not improve from 0.80600\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 29ms/step - accuracy: 0.7887 - loss: 0.6140 - val_accuracy: 0.7976 - val_loss: 0.6432 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7949 - loss: 0.5952\n",
      "Epoch 10: val_accuracy improved from 0.80600 to 0.81490, saving model to ../models/s3/model_trial_3_4_1_DA_CPbest.keras\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7949 - loss: 0.5952 - val_accuracy: 0.8149 - val_loss: 0.5805 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7977 - loss: 0.5853\n",
      "Epoch 11: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 29ms/step - accuracy: 0.7977 - loss: 0.5853 - val_accuracy: 0.8056 - val_loss: 0.6127 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7956 - loss: 0.5973\n",
      "Epoch 12: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7956 - loss: 0.5972 - val_accuracy: 0.7930 - val_loss: 0.6688 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7959 - loss: 0.5926\n",
      "Epoch 13: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.7959 - loss: 0.5925 - val_accuracy: 0.8081 - val_loss: 0.5992 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8009 - loss: 0.5797\n",
      "Epoch 14: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 31ms/step - accuracy: 0.8009 - loss: 0.5797 - val_accuracy: 0.8024 - val_loss: 0.6241 - learning_rate: 1.0000e-05\n",
      "Epoch 15/50\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7949 - loss: 0.5876\n",
      "Epoch 15: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7949 - loss: 0.5876 - val_accuracy: 0.8055 - val_loss: 0.6136 - learning_rate: 1.0000e-05\n",
      "Epoch 16/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7967 - loss: 0.5848\n",
      "Epoch 16: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7967 - loss: 0.5848 - val_accuracy: 0.8073 - val_loss: 0.6102 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7992 - loss: 0.5789\n",
      "Epoch 17: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 29ms/step - accuracy: 0.7992 - loss: 0.5789 - val_accuracy: 0.8061 - val_loss: 0.6157 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m1248/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7956 - loss: 0.5862\n",
      "Epoch 18: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 30ms/step - accuracy: 0.7956 - loss: 0.5862 - val_accuracy: 0.8045 - val_loss: 0.6166 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m1249/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7998 - loss: 0.5783\n",
      "Epoch 19: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 30ms/step - accuracy: 0.7998 - loss: 0.5783 - val_accuracy: 0.8069 - val_loss: 0.6119 - learning_rate: 1.0000e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8021 - loss: 0.5851\n",
      "Epoch 20: val_accuracy did not improve from 0.81490\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 31ms/step - accuracy: 0.8021 - loss: 0.5851 - val_accuracy: 0.8073 - val_loss: 0.6089 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('../models/s3/model_trial_5_DA_CPbest.keras')\n",
    "model_path = '../models/s3/model_trial_5_1_DA_CPbest.keras'\n",
    "\n",
    "callbacks = [\n",
    "    ModelCheckpoint(\n",
    "        filepath=model_path,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    EarlyStopping(\n",
    "        monitor='val_accuracy',\n",
    "        mode='max',\n",
    "        patience=10\n",
    "    ),\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_accuracy', \n",
    "        mode='max',\n",
    "        factor=0.1,  \n",
    "        patience=3,  \n",
    "        min_lr=1e-5\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=50,  \n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "plot_training_history(history, '3', '5_1_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avaliação do modelo 4\n",
    "- 86 épocas no total\n",
    "- Precisão no conjunto de Validação: 81.49%\n",
    "- Perda no conjunto de Validação: 0.5805"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 18:30:06.837999: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 880ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 366ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-22 18:30:31.686168: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "model = models.load_model('../models/s3/model_trial_5_1_DA_CPbest.keras')\n",
    "y_test, pred = predict_with_best_model(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8101 - loss: 0.5772\n",
      "\tPrecião no conjunto de Teste: 0.8078\n",
      "\tPerda no conjunto de Teste:   0.6051\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f'\\tPrecião no conjunto de Teste: {test_acc:.4f}')\n",
    "print(f'\\tPerda no conjunto de Teste:   {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Precisão no conjunto de Teste: 80.8%\n",
    "- Perda no conjunto de Teste: 0.7643\n",
    "\n",
    "O modelo apresenta um desempenho bom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 80.78%\n",
      "\n",
      "Precision:\n",
      "\tMacro:    80.8%\n",
      "\tWeighted: 80.8%\n",
      "\n",
      "Recall:\n",
      "\tMacro:    80.78%\n",
      "\tWeighted: 80.78%\n",
      "\n",
      "\n",
      "F1-score:\n",
      "\tMacro:    80.42%\n",
      "\tWeighted: 80.42%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_true =  y_test, y_pred = pred)\n",
    "print(f'Accuracy : {np.round(acc*100,2)}%')\n",
    "\n",
    "print(\"\\nPrecision:\")   \n",
    "precision = precision_score(y_true =  y_test, y_pred = pred, average='macro')\n",
    "print(f'\\tMacro:    {np.round(precision*100,2)}%')\n",
    "\n",
    "precision = precision_score(y_true =  y_test, y_pred = pred, average='weighted')\n",
    "print(f'\\tWeighted: {np.round(precision*100,2)}%')\n",
    "\n",
    "print(\"\\nRecall:\")\n",
    "recall = recall_score(y_true =  y_test, y_pred = pred, average='macro')\n",
    "print(f'\\tMacro:    {np.round(recall*100,2)}%')\n",
    "\n",
    "recall = recall_score(y_true =  y_test, y_pred = pred, average='weighted')\n",
    "print(f'\\tWeighted: {np.round(recall*100,2)}%')\n",
    "print()\n",
    "\n",
    "print(\"\\nF1-score:\")\n",
    "f1 = f1_score(y_true =  y_test, y_pred = pred, average='macro')\n",
    "print(f'\\tMacro:    {np.round(f1*100,2)}%')\n",
    "\n",
    "f1 = f1_score(y_true =  y_test, y_pred = pred, average='weighted')\n",
    "print(f'\\tWeighted: {np.round(f1*100,2)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resultado Precisão:\n",
    "- Macro: 80.8%\n",
    "- Ponderada: 80.8%\n",
    "\n",
    "A precisão macro e weighted são iguais, indicando que as classes são balanceadas. A precisão de aproximadamente 81% mostra que, quando o modelo prevê uma classe como positiva, ele está correto em 81% dos casos. Indicando que o modelo tem um bom desempenho uniforme em todas as classes.\n",
    "\n",
    "<br>\n",
    "\n",
    "Resultado Revocação:\n",
    "- Macro: 80.78%\n",
    "- Ponderada: 80.78%\n",
    "\n",
    "As métricas de precisão e recall são praticamente iguais, o que é positivo. As versões macro e ponderada são iguais. Logo, o modelo tem uma capacidade uniforme de identificar corretamente as instâncias de cada classe.\n",
    "\n",
    "<br>\n",
    "\n",
    "Resultado F1-Score:\n",
    "- Macro: 80.42%\n",
    "- Ponderada: 80.42%\n",
    "\n",
    "O valor de 80.42% para ambas as versões indica que o modelo mantém um bom equilíbrio entre precisão e recall, embora seja ligeiramente menor, indicando uma pequena margem para melhorias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Avião', 'Automovel', 'Passaro', 'Gato', 'Viado',\n",
    "                'Cão', 'Sapo', 'Cavalo', 'Barco', 'Camião']\n",
    "plot_confusion_matrix(y_test, pred, class_names, '3', '5_1_DA')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../plots/s3/trial_5_1_DA_confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusões Finais\n",
    "\n",
    "O modelo agora apresenta uma acurácia, precisão, recall e F1-score acima de 80%, indicando uma melhora considerável com data augmentation. Mas seria possivel continuar monitorando e ajustando hiperparâmetros, além de realizar validação cruzada, podem levar a melhorias adicionais e garantir a estabilidade do modelo em diferentes conjuntos de dados.\n",
    "\n",
    "Porém para este projeto iremos ficar por aqui com os modelos S"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
